{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#Tokenize text\n",
    "from konlpy.tag import Kkma \n",
    "from konlpy.utils import pprint \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ParseText:\n",
    "    def __init__(self):\n",
    "        self.dir=\"\"\n",
    "        self.stopwords=pd.DataFrame(columns=['vocab','pos'])\n",
    "        self.data=[]\n",
    "        self.parsedData=[]\n",
    "        self.kkma=None\n",
    "        \n",
    "    def openAllJsonTest(self,dirname,limit=0): #\"./2020-02-019.도서자료요약_Sample\"\n",
    "        self.dir+=dirname## get path\n",
    "        #1) open json file\n",
    "        jsonobj=[]\n",
    "        \n",
    "        for file in os.listdir(dirname):\n",
    "            if limit<0:\n",
    "                break\n",
    "            jsonfd=open(dirname+\"/\"+file, encoding=\"utf-8\")## get file descriptor\n",
    "            jsonstr=jsonfd.read()## get str\n",
    "            jsonobj.append(jsonstr)\n",
    "            limit-=1\n",
    "        \n",
    "        return jsonobj\n",
    "    def openAllJson(self,dirname): #\"./2020-02-019.도서자료요약_Sample\"\n",
    "        self.dir+=dirname## get path\n",
    "        #1) open json file\n",
    "        jsonobj=[]\n",
    "        \n",
    "        for file in os.listdir(dirname):\n",
    " \n",
    "            jsonfd=open(dirname+\"/\"+file, encoding=\"utf-8\")## get file descriptor\n",
    "            jsonstr=jsonfd.read()## get str\n",
    "            jsonobj.append(jsonstr)\n",
    "\n",
    "        \n",
    "        return jsonobj\n",
    "    \n",
    "    def organizeFile(self,jsonobj):\n",
    "\t\t#2) select passages and summaries\n",
    "        file=json.loads(jsonobj)\n",
    "        return {'id':file[\"passage_id\"],'passage':file[\"passage\"],'summary':file[\"summary\"]}\n",
    "    \n",
    "    def organizeFiles(self,dirname):\n",
    "        jsonobj=self.openAllJson(dirname)\n",
    "        for i in range(len(jsonobj)):\n",
    "            self.data.append(self.organizeFile(jsonobj[i]))\n",
    "    def organizeFilesTest(self,dirname,limit=10):\n",
    "            jsonobj=self.openAllJsonTest(dirname,limit=limit)\n",
    "            for i in range(len(jsonobj)):\n",
    "                self.data.append(self.organizeFile(jsonobj[i]))\n",
    "        \n",
    "    \n",
    "    def setStopwords(self,path):#stopwords.txt\n",
    "        self.kkma=Kkma()\n",
    "        f=open(path,encoding=\"utf-8\")\n",
    "        self.stopwords=pd.concat((self.stopwords,pd.DataFrame(self.kkma.pos(f.read()),columns=['vocab','pos'])),axis=0)\n",
    "    \n",
    "    def preprocessFile(self,data):\n",
    "        kkma=Kkma()\n",
    "        passage=data['passage']\n",
    "        word_dict=pd.DataFrame(columns=['vocab','pos','mundan_id','sent_id','eojeol_id'])\n",
    "        for i,mundan in enumerate(passage.split('\\n')): #i는 n 번째 문단이라는 뜻\n",
    "            for j, sent in enumerate(mundan.split('.')):#j 는 n번째 문장이라는 뜻\n",
    "                for k, word in enumerate(sent.split(' ')):#k는 n번째 어절이라는 뜻 \n",
    "                    passage_hs=kkma.pos(word) #list in list\n",
    "                    for hs in passage_hs: #어절 내부의 위치는 기록하지 않는다. 어절은 통째로 뺄 것이기 때문이다. \n",
    "                        position=[i,j,k]+list(hs)\n",
    "                        current=np.reshape(np.array(position),(1,-1))\n",
    "                        current=pd.DataFrame(current,columns=['mundan_id','sent_id','eojeol_id','vocab','pos'])\n",
    "                        word_dict=pd.concat((word_dict,current),axis=0)\n",
    "\n",
    "                \n",
    "\n",
    "        return word_dict\n",
    "\n",
    "\n",
    "    def preprocessFiles(self,stoppath,stop=0):\n",
    "        if stop==0:\n",
    "            self.setStopwords(stoppath)\n",
    "        #new passage object with words-->words & PoS tuples / only NNG, VV\n",
    "        for d in self.data:\n",
    "            word_PoS_pos=self.preprocessFile(d)\n",
    "            #품사,stopwords 필터, 재정렬\n",
    "            filtered=word_PoS_pos[(word_PoS_pos.pos=='NNG')|(word_PoS_pos.pos=='VV')&(~word_PoS_pos['vocab'].isin(list(self.stopwords.vocab)))].reset_index()\n",
    "            self.parsedData.append(filtered)\n",
    "        return self.parsedData\n",
    "    \n",
    "    def doAll(self,type=0,dr=None,stop=None):\n",
    "        if type==0:\n",
    "            dirname=input('dirname of jsonobj directory')\n",
    "            stoppath=input('dirname of stopwords txt')\n",
    "        else:\n",
    "            dirname=dr\n",
    "            stoppath=stop\n",
    "        self.organizeFiles(dirname)\n",
    "        data_stack=self.preprocessFiles(stoppath)\n",
    "        return data_stack\n",
    "    def doAllTest(self,dirname,stoppath,limit):\n",
    "\n",
    "        self.organizeFilesTest(dirname,limit=limit)\n",
    "        data_stack=self.preprocessFiles(stoppath)\n",
    "        return data_stack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser2=ParseText()\n",
    "result=parser2.doAllTest(\"./2020-02-019.도서자료요약_Sample\",\"stopwords.txt\",limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    index vocab  pos mundan_id sent_id eojeol_id\n",
       " 0       0    선거  NNG         0       0         1\n",
       " 1       0    개혁  NNG         0       0         1\n",
       " 2       0    유사  NNG         0       0         2\n",
       " 3       0    문제  NNG         0       0         3\n",
       " 4       0   유권자  NNG         0       1         1\n",
       " ..    ...   ...  ...       ...     ...       ...\n",
       " 81      0    참여  NNG         0       4         6\n",
       " 82      0    확대  NNG         0       4         7\n",
       " 83      0     전  NNG         0       4         8\n",
       " 84      0   나아지   VV         0       4         9\n",
       " 85      0    한계  NNG         0       4        13\n",
       " \n",
       " [86 rows x 6 columns],\n",
       "     index vocab  pos mundan_id sent_id eojeol_id\n",
       " 0       0   종교가  NNG         0       0         1\n",
       " 1       0    인간  NNG         0       0         2\n",
       " 2       0     꿈  NNG         0       0         3\n",
       " 3       0    실현  NNG         0       0         4\n",
       " 4       0    해답  NNG         0       0         5\n",
       " ..    ...   ...  ...       ...     ...       ...\n",
       " 75      0   종교가  NNG         0       7         9\n",
       " 76      0   보여주   VV         0       7        10\n",
       " 77      0    역사  NNG         0       7        12\n",
       " 78      0   문화적  NNG         0       7        12\n",
       " 79      0    현상  NNG         0       7        13\n",
       " \n",
       " [80 rows x 6 columns],\n",
       "      index vocab  pos mundan_id sent_id eojeol_id\n",
       " 0        0   절대적  NNG         0       0         1\n",
       " 1        0     힘  NNG         0       0         2\n",
       " 2        0    만남  NNG         0       0         3\n",
       " 3        0     힘  NNG         0       0         5\n",
       " 4        0    제시  NNG         0       0         6\n",
       " ..     ...   ...  ...       ...     ...       ...\n",
       " 109      0     힘  NNG         0       9         9\n",
       " 110      0     터  NNG         0       9         9\n",
       " 111      0    도움  NNG         0       9        10\n",
       " 112      0    거절  NNG         0       9        11\n",
       " 113      0     일  NNG         0       9        14\n",
       " \n",
       " [114 rows x 6 columns],\n",
       "     index vocab  pos mundan_id sent_id eojeol_id\n",
       " 0       0    서술  NNG         0       0         7\n",
       " 1       0     수  NNG         0       0         8\n",
       " 2       0    사물  NNG         0       0        12\n",
       " 3       0    인식  NNG         0       0        15\n",
       " 4       0     수  NNG         0       0        17\n",
       " ..    ...   ...  ...       ...     ...       ...\n",
       " 82      0   주관적  NNG         0       6        14\n",
       " 83      0    인식  NNG         0       6        15\n",
       " 84      0    과오  NNG         0       6        16\n",
       " 85      0   벗어나   VV         0       6        18\n",
       " 86      0     수  NNG         0       6        19\n",
       " \n",
       " [87 rows x 6 columns],\n",
       "     index vocab  pos mundan_id sent_id eojeol_id\n",
       " 0       0    주목  NNG         0       0         1\n",
       " 1       0    종교  NNG         0       0         3\n",
       " 2       0    문화  NNG         0       0         3\n",
       " 3       0    죽음  NNG         0       0         4\n",
       " 4       0    담론  NNG         0       0         4\n",
       " ..    ...   ...  ...       ...     ...       ...\n",
       " 94      0    끝나   VV         0      14        10\n",
       " 95      0   이어지   VV         0      14        11\n",
       " 96      0    저승  NNG         0      14        12\n",
       " 97      0     삶  NNG         0      14        13\n",
       " 98      0    설명  NNG         0      14        14\n",
       " \n",
       " [99 rows x 6 columns]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank():\n",
    "    def __init__(self,data):\n",
    "        self.nodes=data\n",
    "        self.edges=[]\n",
    "    def makeEdge(self, window=5):\n",
    "        #for all passages\n",
    "        for df in self.nodes:\n",
    "            #list \n",
    "            #for all window size\n",
    "            for i in range(1,window+1):\n",
    "                for index in range(0,df.shape[0]-i):\n",
    "                    # for all words in passages\n",
    "                    self.edges.append((df.loc[index,'vocab'],df.loc[index+i,'vocab']))\n",
    "    return edges\n",
    "    def flip(self):\n",
    "        processed_edges=edges\n",
    "        edges_set=[]\n",
    "        for i,edge in enumerate(edges):\n",
    "            if edge not in edges_set:\n",
    "                if edge[::-1] not in edges_set:\n",
    "                    edges_set.append(edge)\n",
    "                else:\n",
    "                    processed_edges.pop(i)\n",
    "                    processed_edges.insert(i,edge[::-1])\n",
    "        return edges,edges_set\n",
    "    \n",
    "    def connectEdge(self):\n",
    "        vocab=passage_w_pos[0]['vocab']\n",
    "        vocab=vocab.drop_duplicates()\n",
    "        vocab=vocab.reset_index()\n",
    "        vocab.drop('index',inplace=True,axis=1)\n",
    "\n",
    "        print(vocab.size)\n",
    "        #2) make co relationship matrx of vocab*vocab\n",
    "        rel_matrix=np.zeros((vocab.size,vocab.size))\n",
    "\n",
    "        for pair in counter:\n",
    "            w1,w2=pair\n",
    "            #한 integer가 나올 것이다. \n",
    "            p1=vocab.loc[vocab['vocab']==w1].index.tolist()\n",
    "            p2=vocab.loc[vocab['vocab']==w2].index.tolist()\n",
    "            #3) use counter to fill in the matrix\n",
    "            count=counter[pair]\n",
    "            rel_matrix[p1[0]][p2[0]]+=count\n",
    "\n",
    "            \n",
    "\n",
    "        #4) normalize matrix only the rows\n",
    "            # if directed, omit \"reduce_flip_edges\" stage and make the matrix accordingly\n",
    "\n",
    "        norm=np.linalg.norm(rel_matrix)\n",
    "        rel_matrix=rel_matrix/norm\n",
    "        \n",
    "        #5) make iterative calculation starting with dot of n*n   with [1....1] (n*1 size)\n",
    "        iteration=10\n",
    "        im_vec=np.ones(rel_matrix.shape[0])\n",
    "        for i in range(iteration):\n",
    "    im_vec=np.dot(rel_matrix,im_vec)\n",
    "    \n",
    "    def returnBest(self,best_count):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b485adf93bff8ca269d5493edbedeaa1a759650bfde9cbea36fd7f7b559c92d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
