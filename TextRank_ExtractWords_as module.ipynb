{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#Tokenize text\n",
    "from konlpy.tag import Kkma \n",
    "from konlpy.utils import pprint \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class parseText:\n",
    "    def __init__(self):\n",
    "        self.dir=\"\"\n",
    "        self.stopwords=pd.DataFrame(colums=['vocab','pos'])\n",
    "        self.data=[]\n",
    "        self.parsedData=[]\n",
    "        self.kkma=None\n",
    "        \n",
    "    def openAllJson(self,dirname): #\"./2020-02-019.도서자료요약_Sample\"\n",
    "        self.dir+=dirname## get path\n",
    "        #1) open json file\n",
    "        jsonobj=[]\n",
    "        for file in os.listdir(dirname):\n",
    "            jsonfd=open(dirname+\"/\"+file, encoding=\"utf-8\")## get file descriptor\n",
    "            jsonstr=jsonfd.read()## get str\n",
    "            jsonobj.append(jsonstr)\n",
    "        \n",
    "        return jsonobj\n",
    "    \n",
    "    def organizeFile(self,jsonobj):\n",
    "\t\t#2) select passages and summaries\n",
    "        return {'id':jsonobj[\"passage_id\"],'passage':jsonobj[\"passage\"],'summary':jsonobj[\"summary\"]}\n",
    "    \n",
    "    def organaizeFiles(self,dirname):\n",
    "        jsonobj=self.openAllJson(dirname)\n",
    "        for i in range(len(jsonobj)):\n",
    "            self.data.append(self.organizeFile(jsonobj[i]))\n",
    "    \n",
    "    def setStopwords(self,path):#stopwords.txt\n",
    "        self.kkma=Kkma()\n",
    "        f=open(path,encoding=\"utf-8\")\n",
    "        self.stopwords=pd.concat((self.stopwords,pd.DataFrame(self.kkma.pos(f.read()),columns=['vocab','pos'])),axis=0)\n",
    "    \n",
    "    def preprocessFile(self,data):\n",
    "        passage=data['passage']\n",
    "        word_dict=pd.DataFrame(columns=['vocab','pos','mundan_id','sent_id','eojeol_id'])\n",
    "        for i,mundan in enumerate(passage.split('\\n')): #i는 n 번째 문단이라는 뜻\n",
    "            position=(i)\n",
    "            for j, sent in enumerate(mundan.split('.')):#j 는 n번째 문장이라는 뜻\n",
    "                position+=(j)\n",
    "                for k, word in enumerate(sent.split(' ')):#k는 n번째 어절이라는 뜻 \n",
    "                    position+=(k)\n",
    "                    passage_hs=kkma.pos(word) #list in list\n",
    "                    for hs in passage_hs:\n",
    "                        current=pd.DataFrame(position+hs,columns=['vocab','pos','mundan_id','sent_id','eojeol_id'])\n",
    "                        word_dict=pd.concat((word_dict,current),axis=0)\n",
    "        return word_dict\n",
    "\n",
    "\n",
    "    def preprocessFiles(self,stoppath):\n",
    "        self.setStopwords(stoppath)\n",
    "        #new passage object with words-->words & PoS tuples / only NNG, VV\n",
    "        for d in self.data:\n",
    "            word_PoS_pos=self.preprocessFile(d)\n",
    "            #품사,stopwords 필터, 재정렬\n",
    "            filtered=word_PoS_pos[(word_PoS_pos.pos=='NNG')|(word_PoS_pos.pos=='VV')&(~word_PoS_pos['vocab'].isin(list(self.stopwords.vocab)))].reset_index()\n",
    "            self.parsedData.append(filtered)\n",
    "        return self.parsedData\n",
    "    \n",
    "    def doAll(self):\n",
    "        dirname=input('dirname of jsonobj directory')\n",
    "        stoppath=input('dirname of stopwords txt')\n",
    "        self.organaizeFiles(dirname)\n",
    "        self.preprocessFiles(stoppath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma=Kkma()\n",
    "f=open('testParse.txt','r')\n",
    "fstr=f.read()\n",
    "fstrs=fstr.split('\\n')\n",
    "f_wpos=kkma.pos(fstr) #전체 문단에 대한 pos\n",
    "fstrs_wpos=[kkma.pos(s) for s in fstrs] #각 문장에 대한 pos\n",
    "\n",
    "for sent in fstrs_wpos:\n",
    "\ta=pd.DataFrame(sent,columns=['vocab','pos'])\n",
    "\ta['sent_id']=1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
